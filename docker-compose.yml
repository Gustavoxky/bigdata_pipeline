services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper

  spark:
    build:
      context: . # O contexto Ã© a raiz do projeto
      dockerfile: docker/spark/Dockerfile
    container_name: spark
    ports:
      - "8081:8080" # Evitar conflitos de porta
    environment:
      SPARK_MASTER_HOST: spark
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
    networks:
      - hadoop-net

  airflow:
    image: apache/airflow:2.6.3
    container_name: airflow
    ports:
      - "8082:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
    environment:
      AIRFLOW_UID: 50000
    command: >
      bash -c "airflow db init &&
      airflow webserver"
    networks:
      - hadoop-net

  hadoop:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop
    hostname: hadoop
    environment:
      - CLUSTER_NAME=test
    ports:
      - "50070:50070"
      - "9000:9000"
    networks:
      - hadoop-net

networks:
  hadoop-net:
    driver: bridge
